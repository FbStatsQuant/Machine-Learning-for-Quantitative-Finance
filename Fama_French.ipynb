{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.linalg import toeplitz\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            Excess_AAPL   R-squared:                       0.660\n",
      "Model:                            OLS   Adj. R-squared:                  0.660\n",
      "Method:                 Least Squares   F-statistic:                     1055.\n",
      "Date:                Sat, 15 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        12:46:22   Log-Likelihood:                 4979.0\n",
      "No. Observations:                1632   AIC:                            -9950.\n",
      "Df Residuals:                    1628   BIC:                            -9928.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0005      0.000      1.652      0.099   -8.78e-05       0.001\n",
      "Mkt-RF         1.1930      0.022     53.195      0.000       1.149       1.237\n",
      "SMB           -0.3020      0.041     -7.348      0.000      -0.383      -0.221\n",
      "HML           -0.3887      0.028    -14.083      0.000      -0.443      -0.335\n",
      "==============================================================================\n",
      "Omnibus:                      289.332   Durbin-Watson:                   1.900\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2581.656\n",
      "Skew:                           0.555   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.061   Cond. No.                         146.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the date range for historical data\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2024-06-30'\n",
    "\n",
    "# Download stock and market index prices (AAPL & SPY as market proxy)\n",
    "data = yf.download(['AAPL', 'SPY'], start=start_date, end=end_date, progress=False)['Close']\n",
    "\n",
    "# Compute daily percentage returns\n",
    "returns = data.pct_change().dropna()\n",
    "returns.columns = ['AAPL_Return', 'Market_Return']\n",
    "\n",
    "# URL for Fama-French factors dataset\n",
    "ff_url = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_daily_CSV.zip\"\n",
    "\n",
    "# Load Fama-French data\n",
    "ff_data = pd.read_csv(ff_url, skiprows=3)  # Skip metadata rows\n",
    "\n",
    "# Rename first column to 'Date' and filter numeric values only\n",
    "ff_data = ff_data.rename(columns={ff_data.columns[0]: \"Date\"})\n",
    "ff_data = ff_data[ff_data['Date'].str.isnumeric()]  # Remove non-date rows\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "ff_data['Date'] = pd.to_datetime(ff_data['Date'], format='%Y%m%d')\n",
    "\n",
    "# Set 'Date' as the index and scale percentage values to decimal format\n",
    "ff_data = ff_data.set_index('Date')\n",
    "ff_data = ff_data.astype(float) / 100  # Convert from percentage format\n",
    "\n",
    "# Align Fama-French data with stock returns time range\n",
    "start_date = returns.index.min()\n",
    "end_date = returns.index.max()\n",
    "ff_data = ff_data.loc[start_date:end_date]  \n",
    "\n",
    "# Merge stock returns with Fama-French factors (Market-RF, SMB, HML, RF)\n",
    "returns = returns.merge(ff_data[['Mkt-RF', 'SMB', 'HML', 'RF']], left_index=True, right_index=True)\n",
    "\n",
    "# Compute excess returns for AAPL and the market\n",
    "returns['Excess_AAPL'] = returns['AAPL_Return'] - returns['RF']\n",
    "returns['Excess_Market'] = returns['Market_Return'] - returns['RF']\n",
    "\n",
    "# Define independent variables (Fama-French three factors)\n",
    "X = returns[['Mkt-RF', 'SMB', 'HML']]\n",
    "X = sm.add_constant(X)  # Add intercept term\n",
    "\n",
    "# Define dependent variable (excess return of AAPL)\n",
    "y = returns['Excess_AAPL']\n",
    "\n",
    "# Fit the Fama-French three-factor model using OLS regression\n",
    "ff_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print regression summary\n",
    "print(ff_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA Order for Residuals: (0, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Extract residuals from the Fama-French regression model\n",
    "residuals = pd.Series(ff_model.resid)\n",
    "\n",
    "# Function to find the best ARIMA model based on AIC (Akaike Information Criterion)\n",
    "def find_best_arima(data, p_range, d_range, q_range):\n",
    "    best_aic = np.inf  # Initialize AIC with a large value\n",
    "    best_order = None  # Store the best (p, d, q) order\n",
    "    best_model = None  # Store the best ARIMA model\n",
    "\n",
    "    # Iterate through all possible combinations of (p, d, q)\n",
    "    for order in product(p_range, d_range, q_range):\n",
    "        try:\n",
    "            # Fit ARIMA model with current order\n",
    "            model = ARIMA(data, order=order).fit()\n",
    "\n",
    "            # Update best model if the current AIC is lower than the best found so far\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_order = order\n",
    "                best_model = model\n",
    "        except:\n",
    "            continue  # Skip configurations that cause errors\n",
    "\n",
    "    return best_model, best_order  # Return the best model and its order\n",
    "\n",
    "# Define parameter search space for ARIMA (p, d, q)\n",
    "p_range = range(0, 4)  # Autoregressive terms\n",
    "d_range = range(0, 2)  # Differencing terms\n",
    "q_range = range(0, 4)  # Moving average terms\n",
    "\n",
    "# Suppress ARIMA-related warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", message=\".*A date index has been provided.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Non-stationary starting autoregressive parameters.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Non-invertible starting MA parameters found.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Maximum Likelihood optimization failed to converge.*\")\n",
    "\n",
    "# Find the best ARIMA model for residuals\n",
    "model, best_order = find_best_arima(residuals, p_range, d_range, q_range)\n",
    "\n",
    "# Print the best ARIMA model order\n",
    "print(f\"Best ARIMA Order for Residuals: {best_order}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "# Extract variance (sigma²) from the fitted ARIMA model\n",
    "sigma2 = model.scale \n",
    "\n",
    "# Extract AR and MA parameters from the model (handling cases with no parameters)\n",
    "ar_params = model.arparams if model.arparams.size > 0 else np.array([])\n",
    "ma_params = model.maparams if model.maparams.size > 0 else np.array([])\n",
    "\n",
    "# Construct AR and MA polynomials (include leading 1 for stability)\n",
    "ar_poly = np.r_[1, -ar_params] if ar_params.size else np.array([1])\n",
    "ma_poly = np.r_[1, ma_params] if ma_params.size else np.array([1])\n",
    "\n",
    "# Function to compute the autocovariance function (ACF) manually\n",
    "def compute_acovf(ar, ma, sigma2, lags):\n",
    "    \"\"\"\n",
    "    Compute the autocovariance function up to a given number of lags.\n",
    "\n",
    "    Parameters:\n",
    "    - ar: AR polynomial coefficients\n",
    "    - ma: MA polynomial coefficients\n",
    "    - sigma2: Residual variance (sigma²)\n",
    "    - lags: Number of lags to compute\n",
    "\n",
    "    Returns:\n",
    "    - acovf: Autocovariance values up to 'lags'\n",
    "    \"\"\"\n",
    "    acovf = np.zeros(lags)\n",
    "    \n",
    "    # Compute lag-0 variance (based on AR and MA terms)\n",
    "    acovf[0] = sigma2 * (1 + np.sum(ma**2)) / (1 - np.sum(ar**2)) if np.sum(ar**2) < 1 else sigma2\n",
    "\n",
    "    # Compute higher-lag autocovariances using recursion\n",
    "    for lag in range(1, lags):\n",
    "        ar_slice = ar[:min(lag, len(ar))]  # Select AR terms up to current lag\n",
    "        acovf_slice = acovf[:lag][::-1]  # Reverse previous ACF values\n",
    "\n",
    "        # Handle different array lengths by padding with zeros\n",
    "        if len(ar_slice) != len(acovf_slice):\n",
    "            diff = abs(len(ar_slice) - len(acovf_slice))\n",
    "            if len(ar_slice) < len(acovf_slice):\n",
    "                ar_slice = np.pad(ar_slice, (0, diff))\n",
    "            else:\n",
    "                acovf_slice = np.pad(acovf_slice, (0, diff))\n",
    "\n",
    "        # Compute autocovariance using dot product\n",
    "        acovf[lag] = np.dot(ar_slice, acovf_slice)\n",
    "\n",
    "    return acovf\n",
    "\n",
    "# Compute autocovariances up to the length of residuals\n",
    "acovf = compute_acovf(ar_params, ma_params, sigma2, len(residuals))\n",
    "\n",
    "# Construct the covariance matrix using the Toeplitz structure\n",
    "cov_matrix = toeplitz(acovf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            Excess_AAPL   R-squared:                       0.660\n",
      "Model:                            GLS   Adj. R-squared:                  0.660\n",
      "Method:                 Least Squares   F-statistic:                     1055.\n",
      "Date:                Sat, 15 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        12:46:43   Log-Likelihood:                 4979.0\n",
      "No. Observations:                1632   AIC:                            -9950.\n",
      "Df Residuals:                    1628   BIC:                            -9928.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0005      0.000      1.652      0.099   -8.78e-05       0.001\n",
      "Mkt-RF         1.1930      0.022     53.195      0.000       1.149       1.237\n",
      "SMB           -0.3020      0.041     -7.348      0.000      -0.383      -0.221\n",
      "HML           -0.3887      0.028    -14.083      0.000      -0.443      -0.335\n",
      "==============================================================================\n",
      "Omnibus:                      289.332   Durbin-Watson:                   1.900\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2581.656\n",
      "Skew:                           0.555   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.061   Cond. No.                         146.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#GLS\n",
    "\n",
    "ff_gls = sm.GLS(y, X, sigma=cov_matrix).fit()\n",
    "print(ff_gls.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
